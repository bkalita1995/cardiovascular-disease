{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from  sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  height  weight  ap_hi  ap_lo  cholestrol  gluc  smoke  alco  active  \\\n",
       "0  63.0   155.0    69.0    130     80           2     2      0     0       1   \n",
       "1  61.0   165.0    70.0    120     80           1     1      0     0       1   \n",
       "2  65.0   155.0    62.0    120     80           1     1      0     0       1   \n",
       "3  63.0   158.0    65.0    140     90           3     1      0     0       1   \n",
       "4  63.0   176.0    72.0    130     90           1     3      0     0       1   \n",
       "\n",
       "   cardio  F  \n",
       "0       0  0  \n",
       "1       0  0  \n",
       "2       0  0  \n",
       "3       1  0  \n",
       "4       1  0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Cardio_final_DataSet.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23129, 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholestrol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "      <td>23129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.853647</td>\n",
       "      <td>165.505642</td>\n",
       "      <td>70.573963</td>\n",
       "      <td>125.212417</td>\n",
       "      <td>82.253232</td>\n",
       "      <td>1.307104</td>\n",
       "      <td>1.200873</td>\n",
       "      <td>0.080981</td>\n",
       "      <td>0.046176</td>\n",
       "      <td>0.801288</td>\n",
       "      <td>0.469886</td>\n",
       "      <td>0.368455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.649648</td>\n",
       "      <td>6.002642</td>\n",
       "      <td>5.424584</td>\n",
       "      <td>7.716128</td>\n",
       "      <td>4.155101</td>\n",
       "      <td>0.646935</td>\n",
       "      <td>0.552921</td>\n",
       "      <td>0.272811</td>\n",
       "      <td>0.209870</td>\n",
       "      <td>0.399039</td>\n",
       "      <td>0.499103</td>\n",
       "      <td>0.482396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height        weight         ap_hi         ap_lo  \\\n",
       "count  23129.000000  23129.000000  23129.000000  23129.000000  23129.000000   \n",
       "mean      54.853647    165.505642     70.573963    125.212417     82.253232   \n",
       "std        6.649648      6.002642      5.424584      7.716128      4.155101   \n",
       "min       40.000000    153.000000     60.500000    111.000000     80.000000   \n",
       "25%       51.000000    161.000000     66.000000    120.000000     80.000000   \n",
       "50%       55.000000    165.000000     70.000000    120.000000     80.000000   \n",
       "75%       60.000000    170.000000     75.000000    130.000000     80.000000   \n",
       "max       66.000000    180.000000     80.500000    144.000000     90.000000   \n",
       "\n",
       "         cholestrol          gluc         smoke          alco        active  \\\n",
       "count  23129.000000  23129.000000  23129.000000  23129.000000  23129.000000   \n",
       "mean       1.307104      1.200873      0.080981      0.046176      0.801288   \n",
       "std        0.646935      0.552921      0.272811      0.209870      0.399039   \n",
       "min        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "50%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "75%        1.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max        3.000000      3.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             cardio             F  \n",
       "count  23129.000000  23129.000000  \n",
       "mean       0.469886      0.368455  \n",
       "std        0.499103      0.482396  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        1.000000      1.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['cardio'],axis=1)\n",
    "y=data.cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "23124    0\n",
       "23125    1\n",
       "23126    0\n",
       "23127    1\n",
       "23128    0\n",
       "Name: cardio, Length: 23129, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,y, test_size= 0.2, random_state = 355)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg1=LogisticRegression()\n",
    "log_reg1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6883970257651738"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg1.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X_Scale=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_train,x2_test,y2_train,y2_test = train_test_split(X_Scale,y, test_size= 0.2, random_state = 355)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr=LogisticRegression()\n",
    "lgr.fit(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6954172070903588"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.score(x2_test,y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier()\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6035451794206658"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.score(x_test,y_test)cv="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : range(2,25,3),\n",
    "    'min_samples_leaf' : range(2,10,2),\n",
    "    'min_samples_split': range(2,10,2),\n",
    "    'splitter' : ['best', 'random']\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(estimator=dt_clf,param_grid=grid_param,cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(2, 25, 3),\n",
       "                         'min_samples_leaf': range(2, 10, 2),\n",
       "                         'min_samples_split': range(2, 10, 2),\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 6, 'min_samples_split': 8, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "parm = grid_search.best_params_\n",
    "print(parm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_leaf=8, min_samples_split=7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_leaf= 8, min_samples_split= 7, splitter= 'best')\n",
    "dt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6960657155209684"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_clf=RandomForestClassifier()\n",
    "rt_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6593169044530912"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No of Trees in RF\n",
    "n_estimator=[int(x) for x in np.linspace(start=10, stop=100,num=10)]\n",
    "# No of Features\n",
    "max_features=('auto','sqrt','log2')\n",
    "# Maximum Lavel of tree\n",
    "max_depth=[int(x) for x in np.linspace(10,100,10)]\n",
    "#Minimum no of samples to split the node\n",
    "min_samples_split=[2,5,8,10,12,14]\n",
    "#Minimul no of samples required each leaf node\n",
    "min_samples_leaf=[1,2,4,6,8]\n",
    "\n",
    "\n",
    "rf_param_grid={ \n",
    "    'n_estimators':n_estimator,\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':max_depth,\n",
    "    'min_samples_split':min_samples_split,\n",
    "    'min_samples_leaf':min_samples_leaf,\n",
    "    'bootstrap':['True','False']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       " 'min_samples_split': [2, 5, 8, 10, 12, 14],\n",
       " 'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       " 'bootstrap': ['True', 'False']}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_SCV=GridSearchCV(estimator=rt_clf,param_grid=rf_param_grid,cv=5,verbose=2,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12000 candidates, totalling 60000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   56.5s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5824 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6837 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7930 tasks      | elapsed: 56.7min\n",
      "[Parallel(n_jobs=-1)]: Done 9105 tasks      | elapsed: 65.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11697 tasks      | elapsed: 84.5min\n",
      "[Parallel(n_jobs=-1)]: Done 13114 tasks      | elapsed: 95.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14613 tasks      | elapsed: 108.1min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 117.8min\n",
      "[Parallel(n_jobs=-1)]: Done 17853 tasks      | elapsed: 130.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19594 tasks      | elapsed: 145.6min\n",
      "[Parallel(n_jobs=-1)]: Done 21417 tasks      | elapsed: 160.8min\n",
      "[Parallel(n_jobs=-1)]: Done 23320 tasks      | elapsed: 173.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25305 tasks      | elapsed: 187.1min\n",
      "[Parallel(n_jobs=-1)]: Done 27370 tasks      | elapsed: 201.7min\n",
      "[Parallel(n_jobs=-1)]: Done 29517 tasks      | elapsed: 757.8min\n",
      "[Parallel(n_jobs=-1)]: Done 31744 tasks      | elapsed: 769.6min\n",
      "[Parallel(n_jobs=-1)]: Done 34053 tasks      | elapsed: 784.6min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 799.9min\n",
      "[Parallel(n_jobs=-1)]: Done 38913 tasks      | elapsed: 815.1min\n",
      "[Parallel(n_jobs=-1)]: Done 41464 tasks      | elapsed: 832.1min\n",
      "[Parallel(n_jobs=-1)]: Done 44097 tasks      | elapsed: 849.1min\n",
      "[Parallel(n_jobs=-1)]: Done 46810 tasks      | elapsed: 864.2min\n",
      "[Parallel(n_jobs=-1)]: Done 49605 tasks      | elapsed: 883.0min\n",
      "[Parallel(n_jobs=-1)]: Done 52480 tasks      | elapsed: 910.4min\n",
      "[Parallel(n_jobs=-1)]: Done 55437 tasks      | elapsed: 933.3min\n",
      "[Parallel(n_jobs=-1)]: Done 58474 tasks      | elapsed: 954.6min\n",
      "[Parallel(n_jobs=-1)]: Done 60000 out of 60000 | elapsed: 965.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': ['True', 'False'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
       "                         'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                         'min_samples_split': [2, 5, 8, 10, 12, 14],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                          100]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms=grid_SCV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': 'True',\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': 50,\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 80}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clfr=RandomForestClassifier(bootstrap= 'True',\n",
    " criterion='entropy',\n",
    " max_depth= 50,\n",
    " min_samples_leaf=8,\n",
    " min_samples_split=2,\n",
    " n_estimators= 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap='True', criterion='entropy', max_depth=50,\n",
       "                       min_samples_leaf=8, n_estimators=80)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clfr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7357185321299249"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clfr.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7029831387808041"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clfr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf=XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:58:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6878512753999135"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params={\n",
    "    \"learning_rate\": [0.5,0.10,0.15,0.20,0.25],\n",
    "    \"max_depth\": [3,4,5,6,7,9,10,12,14,15],\n",
    "    \"min_child_weight\": [2,3,5,7,9,10,11,],\n",
    "    \"gamma\": [0.0,0.1,0.2,0.3,0.5],\n",
    "    \"colsample_bytree\":[0.3,0.4,0.5,0.7,0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_classi= RandomizedSearchCV(xgb_clf,param_distributions=xgb_params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1, gamma=0,\n",
       "                                           gpu_id=-1, importance_type='gain',\n",
       "                                           interaction_constraints='',\n",
       "                                           learning_rate=0.300000012,\n",
       "                                           max_delta_step=0, max_depth=6,\n",
       "                                           min_child_weight=1, missing=nan,\n",
       "                                           monotone_constraints='()',\n",
       "                                           n_estimators=100, n_jobs=4,\n",
       "                                           num_pa...\n",
       "                                           reg_alpha=0, reg_lambda=1,\n",
       "                                           scale_pos_weight=1, subsample=1,\n",
       "                                           tree_method='exact',\n",
       "                                           validate_parameters=1,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.7,\n",
       "                                                             0.9],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.5],\n",
       "                                        'learning_rate': [0.5, 0.1, 0.15, 0.2,\n",
       "                                                          0.25],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 9, 10, 12,\n",
       "                                                      14, 15],\n",
       "                                        'min_child_weight': [2, 3, 5, 7, 9, 10,\n",
       "                                                             11]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_classi.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_classi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 7,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.5,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_classi.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=7, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:04:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:07:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:07:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "val_score=cross_val_score(xgb_clf,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6425486 , 0.68540541, 0.62918919, 0.66594595, 0.64216216])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6530502597630028"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6878512753999135"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf2=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.5, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=7, monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:14:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=0.5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf2.fit(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7029130411284656"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf2.score(x2_train,y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7036316472114138"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf2.score(x2_test,y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, I used house cardio to detect chance of cardiovascular disease based on given parameter. I used 4 different learning regressors (Logistic Regression, Random Forest, Dicission Tree, and XgBoost), and we have acheived the best prediction performance using Random Forest(without Scaling) and XGBoost(after Scaling, followed by Gradiant Boosting, and then XgBoost, while Linear Regression, acheived the worst performance of the 4.\n",
    "\n",
    "The best prediction performance was acheived using Random Forest regressor, using all features in the dataset, and resulted in the following metrics:\n",
    "\n",
    "- Mean Absolute Error (MAE): 0.0591\n",
    "- Root mean squared error (RMSE): 0.1717\n",
    "- R-squared Score (R2_Score): 0.8746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
